import { spawn } from 'child_process'
import fs from 'fs'
import path from 'path'
import { getRequiredEnvVar, getBackupRetentionDays, getBackupDir } from './db-helpers'

async function backupDatabase() {
  console.log('ğŸ’¾ Starting database backup...')

  try {
    const BACKUP_DIR = getBackupDir()
    
    // ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    if (!fs.existsSync(BACKUP_DIR)) {
      fs.mkdirSync(BACKUP_DIR, { recursive: true })
      console.log(`ğŸ“ Created backup directory: ${BACKUP_DIR}`)
    }

    const timestamp = new Date().toISOString().replace(/[:.]/g, '-')
    const backupFile = path.join(BACKUP_DIR, `backup-${timestamp}.sql`)

    // ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã‚’å®‰å…¨ã«å–å¾—
    const databaseUrl = getRequiredEnvVar('DATABASE_URL')

    console.log(`ğŸ“¥ Creating backup file: backup-${timestamp}.sql`)

    // pg_dump ã‚’å®‰å…¨ã«å®Ÿè¡Œï¼ˆã‚³ãƒãƒ³ãƒ‰ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–ï¼‰
    await safelyExecutePgDump(databaseUrl, backupFile)

    console.log(`âœ… Backup completed: ${backupFile}`)

    // å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
    cleanOldBackups(BACKUP_DIR)
    
    return backupFile
  } catch (error) {
    console.error('âŒ Backup failed:', error)
    process.exit(1)
  }
}

/**
 * pg_dumpã‚’å®‰å…¨ã«å®Ÿè¡Œï¼ˆã‚³ãƒãƒ³ãƒ‰ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–ï¼‰
 */
function safelyExecutePgDump(databaseUrl: string, outputFile: string): Promise<void> {
  return new Promise((resolve, reject) => {
    // pg_dumpã‚³ãƒãƒ³ãƒ‰ã‚’å®‰å…¨ã«å®Ÿè¡Œ
    const child = spawn('pg_dump', [databaseUrl], {
      stdio: ['inherit', 'pipe', 'inherit']
    })

    // å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ä½œæˆ
    const outputStream = fs.createWriteStream(outputFile)
    
    child.stdout.pipe(outputStream)

    child.on('close', (code) => {
      outputStream.end()
      if (code === 0) {
        resolve()
      } else {
        reject(new Error(`pg_dump exited with code ${code}`))
      }
    })

    child.on('error', (error) => {
      outputStream.end()
      reject(new Error(`pg_dump failed to start: ${error.message}`))
    })
  })
}

function cleanOldBackups(backupDir: string) {
  console.log('ğŸ§¹ Cleaning old backups...')

  try {
    const retentionDays = getBackupRetentionDays()
    const files = fs.readdirSync(backupDir)
    const cutoffDate = new Date()
    cutoffDate.setDate(cutoffDate.getDate() - retentionDays)

    let deletedCount = 0

    files.forEach((file) => {
      if (!file.startsWith('backup-') || !file.endsWith('.sql')) {
        return // ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ä»¥å¤–ã¯ã‚¹ã‚­ãƒƒãƒ—
      }

      const filePath = path.join(backupDir, file)
      
      try {
        const stats = fs.statSync(filePath)
        
        if (stats.mtime < cutoffDate) {
          fs.unlinkSync(filePath)
          console.log(`  âœ“ Deleted old backup: ${file}`)
          deletedCount++
        }
      } catch (fileError) {
        console.warn(`  âš ï¸ Warning: Could not process backup file ${file}:`, fileError)
      }
    })

    if (deletedCount === 0) {
      console.log('  âœ“ No old backups to delete')
    } else {
      console.log(`  âœ“ Deleted ${deletedCount} old backup(s) (retention: ${retentionDays} days)`)
    }
  } catch (error) {
    console.warn('âš ï¸ Warning: Failed to clean old backups:', error)
    // ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å‰Šé™¤ã«å¤±æ•—ã—ã¦ã‚‚ã€ãƒ¡ã‚¤ãƒ³ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‡¦ç†ã¯æˆåŠŸã¨ã™ã‚‹
  }
}

// ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒç›´æ¥å®Ÿè¡Œã•ã‚ŒãŸå ´åˆã®ã¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ
if (require.main === module) {
  backupDatabase()
}

export { backupDatabase, cleanOldBackups }