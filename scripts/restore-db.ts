import { spawn } from 'child_process'
import fs from 'fs'
import path from 'path'
import {
  confirmDestructiveOperation,
  getRequiredEnvVar,
  getBackupDir,
} from './db-helpers'

async function restoreDatabase() {
  const backupFile = process.argv[2]

  if (!backupFile) {
    console.error('âŒ Backup file path is required')
    console.log('Usage: npm run db:restore <backup-file-path>')
    console.log(
      'Example: npm run db:restore backups/backup-2025-06-30T10-30-00-000Z.sql'
    )
    process.exit(1)
  }

  // ç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã¯çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
  const absoluteBackupFile = path.isAbsolute(backupFile)
    ? backupFile
    : path.join(process.cwd(), backupFile)

  if (!fs.existsSync(absoluteBackupFile)) {
    console.error(`âŒ Backup file not found: ${absoluteBackupFile}`)

    // ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º
    const backupDir = getBackupDir()
    if (fs.existsSync(backupDir)) {
      console.log('\nğŸ“ Available backup files:')
      const files = fs
        .readdirSync(backupDir)
        .filter((file) => file.startsWith('backup-') && file.endsWith('.sql'))
        .sort()
        .reverse() // æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¡¨ç¤º

      if (files.length > 0) {
        files.slice(0, 10).forEach((file) => {
          const filePath = path.join(backupDir, file)
          const stats = fs.statSync(filePath)
          console.log(`  - ${file} (${stats.mtime.toISOString()})`)
        })
        if (files.length > 10) {
          console.log(`  ... and ${files.length - 10} more files`)
        }
      } else {
        console.log('  No backup files found')
      }
    }

    process.exit(1)
  }

  // ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
  const validationResult = validateBackupFile(absoluteBackupFile)
  if (!validationResult.isValid) {
    console.error('âŒ Invalid backup file:', validationResult.reason)
    process.exit(1)
  }

  try {
    const databaseUrl = getRequiredEnvVar('DATABASE_URL')

    // ç ´å£Šçš„æ“ä½œã®ç¢ºèªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    const shouldProceed = await confirmDestructiveOperation(
      'Database Restore',
      `This will overwrite the current database with data from: ${path.basename(absoluteBackupFile)}`
    )

    if (!shouldProceed) {
      console.log('âŒ Operation cancelled by user')
      process.exit(0)
    }

    // æœ¬ç•ªç’°å¢ƒã§ã®è¿½åŠ å®‰å…¨ãƒã‚§ãƒƒã‚¯
    if (
      process.env.NODE_ENV === 'production' &&
      process.env.FORCE_RESTORE !== 'true'
    ) {
      console.log('')
      console.log('ğŸ›‘ PRODUCTION ENVIRONMENT DETECTED!')
      console.log('   Run with FORCE_RESTORE=true to bypass this check.')
      process.exit(1)
    }

    console.log('ğŸ—„ï¸  Starting database restore...')

    // ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å®‰å…¨ãªå¾©å…ƒ
    await safelyExecutePsqlRestore(databaseUrl, absoluteBackupFile)

    console.log('âœ… Database restored successfully')

    // Prismaã®åŒæœŸ
    console.log('ğŸ”„ Regenerating Prisma client...')
    await safelyExecuteNpmScript('db:generate')

    console.log('âœ… Prisma client regenerated')
    console.log('')
    console.log('ğŸ‰ Database restore completed successfully!')
    console.log('   The database has been restored from the backup file.')
  } catch (error) {
    console.error('âŒ Restore failed:', error)
    console.log('')
    console.log('ğŸ’¡ Troubleshooting tips:')
    console.log('   1. Make sure PostgreSQL is running')
    console.log('   2. Verify DATABASE_URL is correct')
    console.log('   3. Check if the backup file is valid')
    console.log('   4. Ensure you have sufficient database permissions')
    process.exit(1)
  }
}

/**
 * psqlã‚’å®‰å…¨ã«å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å¾©å…ƒ
 */
function safelyExecutePsqlRestore(
  databaseUrl: string,
  backupFile: string
): Promise<void> {
  return new Promise((resolve, reject) => {
    const child = spawn('psql', [databaseUrl], {
      stdio: ['pipe', 'inherit', 'inherit'],
    })

    const inputStream = fs.createReadStream(backupFile)
    inputStream.pipe(child.stdin)

    child.on('close', (code) => {
      if (code === 0) {
        resolve()
      } else {
        reject(new Error(`psql exited with code ${code}`))
      }
    })

    child.on('error', (error) => {
      reject(new Error(`psql failed to start: ${error.message}`))
    })
  })
}

/**
 * npmã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®‰å…¨ã«å®Ÿè¡Œ
 */
function safelyExecuteNpmScript(script: string): Promise<void> {
  return new Promise((resolve, reject) => {
    const child = spawn('npm', ['run', script], {
      stdio: 'inherit',
    })

    child.on('close', (code) => {
      if (code === 0) {
        resolve()
      } else {
        reject(new Error(`npm run ${script} exited with code ${code}`))
      }
    })

    child.on('error', (error) => {
      reject(new Error(`npm run ${script} failed to start: ${error.message}`))
    })
  })
}

// ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
function validateBackupFile(filePath: string): {
  isValid: boolean
  reason?: string
} {
  try {
    const stats = fs.statSync(filePath)

    // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆç©ºãƒ•ã‚¡ã‚¤ãƒ«ã‚„æ¥µç«¯ã«å°ã•ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å¤–ï¼‰
    if (stats.size < 100) {
      return {
        isValid: false,
        reason: 'File is too small to be a valid backup',
      }
    }

    // ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ãƒã‚§ãƒƒã‚¯
    if (!filePath.endsWith('.sql')) {
      return { isValid: false, reason: 'File must have .sql extension' }
    }

    // ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®åŸºæœ¬ãƒã‚§ãƒƒã‚¯
    const content = fs.readFileSync(filePath, 'utf8', { flag: 'r' })
    const contentSample = content.substring(0, 1000) // æœ€åˆã®1000æ–‡å­—ã‚’ãƒã‚§ãƒƒã‚¯

    // PostgreSQLãƒ€ãƒ³ãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®åŸºæœ¬çš„ãªãƒã‚§ãƒƒã‚¯
    const hasPostgreSQLHeader =
      contentSample.includes('PostgreSQL database dump') ||
      contentSample.includes('-- Dumped from database version')
    const hasSQLCommands =
      contentSample.includes('CREATE TABLE') ||
      contentSample.includes('INSERT INTO') ||
      contentSample.includes('COPY ')

    if (!hasPostgreSQLHeader && !hasSQLCommands) {
      return {
        isValid: false,
        reason: 'File does not appear to be a valid PostgreSQL dump',
      }
    }

    return { isValid: true }
  } catch (error) {
    return { isValid: false, reason: `Failed to validate file: ${error}` }
  }
}

// åˆ©ç”¨å¯èƒ½ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º
function listAvailableBackups(): void {
  const backupDir = getBackupDir()

  if (!fs.existsSync(backupDir)) {
    console.log('ğŸ“ No backup directory found')
    return
  }

  const files = fs
    .readdirSync(backupDir)
    .filter((file) => file.startsWith('backup-') && file.endsWith('.sql'))
    .sort()
    .reverse()

  if (files.length === 0) {
    console.log('ğŸ“ No backup files found')
    return
  }

  console.log('ğŸ“ Available backup files:')
  files.forEach((file, index) => {
    const filePath = path.join(backupDir, file)
    try {
      const stats = fs.statSync(filePath)
      const size = (stats.size / 1024).toFixed(1) + ' KB'
      console.log(
        `  ${index + 1}. ${file} (${stats.mtime.toLocaleDateString()} ${stats.mtime.toLocaleTimeString()}, ${size})`
      )
    } catch (error) {
      console.log(`  ${index + 1}. ${file} (error reading file info)`)
    }
  })
}

// CLIå¼•æ•°ãƒã‚§ãƒƒã‚¯
if (process.argv.includes('--list') || process.argv.includes('-l')) {
  listAvailableBackups()
  process.exit(0)
}

// ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒç›´æ¥å®Ÿè¡Œã•ã‚ŒãŸå ´åˆã®ã¿å¾©å…ƒã‚’å®Ÿè¡Œ
if (require.main === module) {
  restoreDatabase()
}

export { restoreDatabase, validateBackupFile, listAvailableBackups }
